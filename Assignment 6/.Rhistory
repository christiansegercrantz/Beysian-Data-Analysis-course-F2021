res = quantile(data,interval)
return(res)
}
set.seed(4711)
p0 <- rbeta(100000, 5, 95)
p1 <- rbeta(100000, 10, 90)
point_est = posterior_odds_ratio_point_est(p0 = p0, p1 = p1)
interval = posterior_odds_ratio_interval(p0 = p0, p1 = p1, prob = 0.9)
#paste0("The point estimate is: ", round(point_est,digits=2))
#paste0("The interval  is: [", round(interval[1],digits=2), ",", round(interval[2],digits=2),"]")
n0 = 674
y0 = 39
n1 = 680
y1 = 22
prior_alpha = 1
prior_beta = 1
post_alpha0 = prior_alpha + n0 - y0
post_beta0 = prior_beta + y0
post_alpha1 = prior_alpha + n1 - y1
post_beta1 = prior_beta + y1
p0 <- rbeta(100000, post_alpha0, post_beta0)
p1 <- rbeta(100000, post_alpha1, post_beta1)
point_est = posterior_odds_ratio_point_est(p0 = p0, p1 = p1)
interval = posterior_odds_ratio_interval(p0 = p0, p1 = p1, prob = 0.95)
paste0("The point estimate is: ", round(point_est,digits=2))
paste0("The interval  is: [", round(interval[1],digits=2), ",", round(interval[2],digits=2),"]")
ratio = (p1/(1 - p1))/(p0/(1 - p0))
hist(ratio, breaks=50)
abline(v = interval[1], col='red')
abline(v = interval[2], col='red')
abline(v = point_est, col='blue')
prior_alpha = c(0.1,0.5,1,5,100)
prior_beta = prior_alpha
post_alpha0 = numeric(length(prior_alpha))
post_beta0 = numeric(length(prior_alpha))
post_alpha1 = numeric(length(prior_alpha))
post_beta1 = numeric(length(prior_alpha))
p0 = numeric(length(prior_alpha))
p1 = numeric(length(prior_alpha))
point_est = numeric(length(prior_alpha))
interval = numeric(length(prior_alpha)*2)
post_alpha0 = prior_alpha + n0 - y0
post_beta0 = prior_beta + y0
post_alpha1 = prior_alpha + n1 - y1
post_beta1 = prior_beta + y1
for(i in 1:length(prior_alpha)){
p0 <- rbeta(100000, post_alpha0[i], post_beta0[i])
p1 <- rbeta(100000, post_alpha1[i], post_beta1[i])
point_est = posterior_odds_ratio_point_est(p0 = p0, p1 = p1)
interval = posterior_odds_ratio_interval(p0 = p0, p1 = p1, prob = 0.95)
ratio = (p1/(1 - p1))/(p0/(1 - p0))
hist(ratio,
breaks=50,
main=paste0("Histogram using prior alpha = ", prior_alpha[i], " and beta = ", prior_beta[i]),
xlim=c(0,5))
abline(v = interval[1], col='red')
abline(v = interval[2], col='red')
abline(v = point_est, col='blue')
legend(3.5,8000, legend=c("Data", "95-Interval", "Mean"),col=c("grey", "red", "blue"), lty=1, cex=0.8)
}
#rm(list = ls())
data("windshieldy1")
data("windshieldy2")
mu_point_est = function(data){
return(mean(data))
}
n1 = length(windshieldy1)
df1 = n1 - 1
mu1 = mu_point_est(windshieldy1)
scale1 = sqrt(var(windshieldy1)/n1)
n2 = length(windshieldy2)
df2 = n2 - 1
mu2 = mu_point_est(windshieldy2)
scale2 = sqrt(var(windshieldy2)/n2)
n_samples <- 100000
samples1 <- rtnew(n_samples, df=df1, mean = mu1, scale = scale1)
samples2 <- rtnew(n_samples, df=df2, mean = mu2, scale = scale2)
mu_d <- mu1 - mu2
#mu_d = mean(samples1-samples2)
paste0("Difference in the means are: ", mu_d)
mu_d_interval = function(samples1, samples2, prob){
low = (1-prob)/2
high = prob+low
int = c(low,high)
sample = samples1-samples2
res = quantile(sample, int)
}
interval = mu_d_interval(samples1 = samples1, samples2 = samples2, 0.95)
paste0("Interval low: ", round(interval[1],digits=2), " and high: ", round(interval[2],digits=2))
hist(samples1-samples2,
breaks=50)
abline(v = interval[1], col='red')
abline(v = interval[2], col='red')
abline(v = mu_d, col='blue')
legend(0.2 ,8000, legend=c("Data", "95-Interval", "mu_d"),col=c("grey", "red", "blue"), lty=1, cex=0.8)
n = length(windshieldy1)
x = seq(from=10,to=20, by=0.1)
freedom = n-1
density = dtnew(x, freedom, mean=mu, scale=sqrt(var(windshieldy1)+(1+1/n)))
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 3")
library(aaltobda)
data("windshieldy1")
windshieldy_test <- c(13.357, 14.928, 14.896, 14.820)
head(windshieldy1)
mu_point_est = function(data){
return(mean(data))
}
mu_interval = function(data, prob){
mu = mu_point_est(data)
n = length(data)
freedom = n-1
scale = sqrt(var(data)/n)
low = (1-prob)/2
high= 1-low
int = c(low,high)
qt_scl <- qtnew(int,freedom)
res = c(mu + qt_scl[1]*scale, mu + qt_scl[2]*scale)
return(res)
}
mu_point_est(windshieldy_test)
mu_interval(data = windshieldy_test, prob = 0.95)
mu = mu_point_est(windshieldy1)
interval = mu_interval(data = windshieldy1, prob = 0.95)
mu
interval
n = length(windshieldy1)
x = seq(from=12,to=17, by=0.1)
freedom = n-1
density = dtnew(x, freedom, mean=mu, scale=sqrt(var(windshieldy1)/n) )
plot(x,density,
xlab = 'x',
type='l')
abline(v = mu, col = "blue")
abline(v = interval[1], col = "red")
abline(v = interval[2], col = "red")
mu_pred_point_est = function(data){
return(mean(data))
}
mu_pred_interval = function(data, prob){
mu = mu_point_est(data)
n = length(data)
freedom = n-1
scale = sqrt(var(data)/n)
low = (1-prob)/2
high= prob+low
int = c(low,high)
res <- qtnew(int,freedom, mean=mu, scale = scale)
return(res)
}
#Test data:
mu_pred_point_est(data = windshieldy_test)
mu_pred_interval(data = windshieldy_test, prob = 0.95)
mu = mu_pred_point_est(data = windshieldy1)
interval = mu_pred_interval(data = windshieldy1, prob = 0.95)
mu
interval
n = length(windshieldy1)
x = seq(from=10,to=20, by=0.1)
freedom = n-1
density = dtnew(x, freedom, mean=mu, scale=sqrt(var(windshieldy1)+(1+1/n)))
plot(x,density,
xlab = 'x',
type='l')
abline(v = mu, col = "blue")
abline(v = interval[1], col = "red")
abline(v = interval[2], col = "red")
n = length(windshieldy1)
x = seq(from=5,to=25, by=0.1)
freedom = n-1
density = dtnew(x, freedom, mean=mu, scale=sqrt(var(windshieldy1)+(1+1/n)))
plot(x,density,
xlab = 'x',
type='l')
abline(v = mu, col = "blue")
abline(v = interval[1], col = "red")
abline(v = interval[2], col = "red")
mu = mu_pred_point_est(data = windshieldy1)
interval = mu_pred_interval(data = windshieldy1, prob = 0.95)
mu
interval
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 3")
library(aaltobda)
data("windshieldy1")
windshieldy_test <- c(13.357, 14.928, 14.896, 14.820)
head(windshieldy1)
mu_point_est = function(data){
return(mean(data))
}
mu_interval = function(data, prob){
mu = mu_point_est(data)
n = length(data)
freedom = n-1
scale = sqrt(var(data)/n)
low = (1-prob)/2
high= 1-low
int = c(low,high)
qt_scl <- qtnew(int,freedom)
res = c(mu + qt_scl[1]*scale, mu + qt_scl[2]*scale)
return(res)
}
mu_point_est(windshieldy_test)
mu_interval(data = windshieldy_test, prob = 0.95)
mu = mu_point_est(windshieldy1)
interval = mu_interval(data = windshieldy1, prob = 0.95)
mu
interval
n = length(windshieldy1)
x = seq(from=12,to=17, by=0.1)
freedom = n-1
density = dtnew(x, freedom, mean=mu, scale=sqrt(var(windshieldy1)/n) )
plot(x,density,
xlab = 'x',
type='l')
abline(v = mu, col = "blue")
abline(v = interval[1], col = "red")
abline(v = interval[2], col = "red")
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 3")
library(aaltobda)
data("windshieldy1")
windshieldy_test <- c(13.357, 14.928, 14.896, 14.820)
head(windshieldy1)
mu_point_est = function(data){
return(mean(data))
}
mu_interval = function(data, prob){
mu = mu_point_est(data)
n = length(data)
freedom = n-1
scale = sqrt(var(data)/n)
low = (1-prob)/2
high= 1-low
int = c(low,high)
qt_scl <- qtnew(int,freedom)
res = c(mu + qt_scl[1]*scale, mu + qt_scl[2]*scale)
return(res)
}
mu_point_est(windshieldy_test)
mu_interval(data = windshieldy_test, prob = 0.95)
mu = mu_point_est(windshieldy1)
interval = mu_interval(data = windshieldy1, prob = 0.95)
mu
interval
n = length(windshieldy1)
x = seq(from=12,to=17, by=0.1)
freedom = n-1
density = dtnew(x, freedom, mean=mu, scale=sqrt(var(windshieldy1)/n) )
plot(x,density,
xlab = 'x',
type='l')
abline(v = mu, col = "blue")
abline(v = interval[1], col = "red")
abline(v = interval[2], col = "red")
mu_pred_point_est = function(data){
return(mean(data))
}
mu_pred_interval = function(data, prob){
mu = mu_point_est(data)
n = length(data)
freedom = n-1
scale = sqrt(var(data)+(1+1/n))
low = (1-prob)/2
high= prob+low
int = c(low,high)
res <- qtnew(int,freedom, mean=mu, scale = scale)
return(res)
}
#Test data:
mu_pred_point_est(data = windshieldy_test)
mu_pred_interval(data = windshieldy_test, prob = 0.95)
mu = mu_pred_point_est(data = windshieldy1)
interval = mu_pred_interval(data = windshieldy1, prob = 0.95)
mu
interval
mu_pred_point_est = function(data){
return(mean(data))
}
mu_pred_interval = function(data, prob){
mu = mu_point_est(data)
n = length(data)
freedom = n-1
scale = 1/(n-1)*sum((data-mu)Ë†2)
mu_pred_point_est = function(data){
return(mean(data))
}
mu_pred_interval = function(data, prob){
mu = mu_point_est(data)
n = length(data)
freedom = n-1
scale = 1/(n-1)*sum((data-mu)^2)
low = (1-prob)/2
high= prob+low
int = c(low,high)
res <- qtnew(int,freedom, mean=mu, scale = scale)
return(res)
}
mu = mu_pred_point_est(data = windshieldy1)
interval = mu_pred_interval(data = windshieldy1, prob = 0.95)
mu
interval
n = length(windshieldy1)
x = seq(from=5,to=25, by=0.1)
freedom = n-1
density = dtnew(x, freedom, mean=mu, scale=sqrt(var(windshieldy1)+(1+1/n)))
plot(x,density,
xlab = 'x',
type='l')
abline(v = mu, col = "blue")
abline(v = interval[1], col = "red")
abline(v = interval[2], col = "red")
n = length(windshieldy1)
x = seq(from=5,to=25, by=0.1)
freedom = n-1
density = dtnew(x, freedom, mean=mu, scale=1/(n-1)*sum((windshieldy1-mu)^2))
plot(x,density,
xlab = 'x',
type='l')
abline(v = mu, col = "blue")
abline(v = interval[1], col = "red")
abline(v = interval[2], col = "red")
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 5")
library(aaltobda)
data("bioassay")
library("rstan")
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 5")
library(aaltobda)
data("bioassay")
library("rstan")
install.packages("matrixStats")
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 5")
library(aaltobda)
data("bioassay")
library("rstan")
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 5")
library(aaltobda)
data("bioassay")
library("rstan")
corr = 0.6
a_std = 2
b_std = 10
mu = c(0,10)
sigma = matrix( c(a_std^2, a_std*b_std*corr, a_std*b_std*corr, b_std^2),nrow = 2)
density_ratio = function(alpha_propose, alpha_previous, beta_propose, beta_previous, x, y, n){
likli_propose <- bioassaylp(alpha_propose, beta_propose, x, y, n)
likli_previous <- bioassaylp(alpha_previous, beta_previous, x, y, n)
prior_prop <- dmvnorm(c(alpha_propose,beta_propose),mu, sigma, log = TRUE)
prior_prev <- dmvnorm(c(alpha_previous,beta_previous),mu, sigma, log = TRUE)
prop = prior_prop + likli_propose
prev = prior_prev + likli_previous
res = exp(prop - prev)
return(res)
}
#Test1
density_ratio(alpha_propose = 1.89, alpha_previous = 0.374,
beta_propose = 24.76, beta_previous = 20.04,
x = bioassay$x, y = bioassay$y, n = bioassay$n)
#Test2
density_ratio(alpha_propose = 0.374, alpha_previous = 1.89,
beta_propose = 20.04, beta_previous = 24.76,
x = bioassay$x, y = bioassay$y, n = bioassay$n)
Metropolis_bioassay = function(n, alpha_previous, beta_previous, warmup_procent = 0.5){
alphas = c()
betas = c()
for( i in 1:n){
alpha_propose = rnorm(1, alpha_previous, 1)
beta_propose = rnorm(1, beta_previous, 5)
r = density_ratio(alpha_propose = alpha_propose, alpha_previous = alpha_previous, beta_propose = beta_propose, beta_previous = beta_previous, x = bioassay$x, y = bioassay$y, n = bioassay$n)
r = min(1,r)
if(r >= runif(1)){
alpha_previous = alpha_propose
beta_previous = beta_propose
}
alphas[i] = alpha_previous
betas[i] = beta_previous
}
alpha_final = na.omit(alphas[n*warmup_procent+1:n])
beta_final = na.omit(betas[n*warmup_procent+1:n])
return(cbind(alpha_final,beta_final))
}
n=2000
warmup_procent = 0.5
thetas1 = Metropolis_bioassay(n, 0, 10, warmup_procent)
thetas2 = Metropolis_bioassay(n, 2, 15, warmup_procent)
thetas3 = Metropolis_bioassay(n, -2, 5, warmup_procent)
plot(thetas1[,1],
type='l',
col='red',
ylab='alpha')
lines(thetas2[,1],
type='l',
col='blue')
lines(thetas3[,1],
type='l',
col='black')
plot(thetas1[,2],
type='l',
col='red',
ylab='beta')
lines(thetas2[,2],
type='l',
col='blue')
lines(thetas3[,2],
type='l',
col='black')
alphas = cbind(thetas1[,1],thetas2[,1],thetas3[,1])
alpha_Rhat = Rhat(alphas)
betas = cbind(thetas1[,2],thetas2[,2],thetas3[,2])
betas_Rhat = Rhat(betas)
plot(thetas1[,1], thetas1[,2], col='red')
points(thetas2[,1], thetas2[,2], col='red')
points(thetas3[,1], thetas3[,2], col='red')
plot(thetas1[,1], thetas1[,2],
col='red',
xlab='alpha',
ylab="beta")
points(thetas2[,1], thetas2[,2], col='red')
points(thetas3[,1], thetas3[,2], col='red')
plot(thetas1[,1], thetas1[,2],
col='red',
xlab='alpha',
ylab="beta",
main="Draws of the parameters")
points(thetas2[,1], thetas2[,2], col='red')
points(thetas3[,1], thetas3[,2], col='red')
install.packages("Rstan")
install.packages("rstan")
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 6")
library(aaltobda)
library("rstan")
data("bioassay")
corr = 0.6
a_std = 2
b_std = 10
mu = c(0,10)
sigma = matrix( c(a_std^2, a_std*b_std*corr, a_std*b_std*corr, b_std^2),nrow = 2)
data <- list(
N = length(bioassay$x), #Number of data points
x = bioassay$x,         #Outcome
n = bioassay$n,         #Total draws
y = bioassay$y,         #Successes
mu = mu,                #Mean vector
sigma = sigma           #Covariance matrix
)
fit1 = sampling(stanmodel,
data = data,            # named list of data
chains = 4,             # number of Markov chains
warmup = 1000,          # number of warmup iterations per chain
iter = 2000,            # total number of iterations per chain
cores = 1,              # number of cores (could use one per chain)
refresh = 0             # no progress shown
)
install.packages("withr")
install.packages("withr")
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 6")
library(aaltobda)
library("rstan")
data("bioassay")
corr = 0.6
a_std = 2
b_std = 10
mu = c(0,10)
sigma = matrix( c(a_std^2, a_std*b_std*corr, a_std*b_std*corr, b_std^2),nrow = 2)
data <- list(
N = length(bioassay$x), #Number of data points
x = bioassay$x,         #Outcome
n = bioassay$n,         #Total draws
y = bioassay$y,         #Successes
mu = mu,                #Mean vector
sigma = sigma           #Covariance matrix
)
fit1 = sampling(stanmodel,
data = data,            # named list of data
chains = 4,             # number of Markov chains
warmup = 1000,          # number of warmup iterations per chain
iter = 2000,            # total number of iterations per chain
cores = 1,              # number of cores (could use one per chain)
refresh = 0             # no progress shown
)
rm(list = ls())
setwd("~/GitHub/Beysian-Data-Analysis-course-F2021/Assignment 6")
library(aaltobda)
library("rstan")
data("bioassay")
corr = 0.6
a_std = 2
b_std = 10
mu = c(0,10)
sigma = matrix( c(a_std^2, a_std*b_std*corr, a_std*b_std*corr, b_std^2),nrow = 2)
data <- list(
N = length(bioassay$x), #Number of data points
x = bioassay$x,         #Outcome
n = bioassay$n,         #Total draws
y = bioassay$y,         #Successes
mu = mu,                #Mean vector
sigma = sigma           #Covariance matrix
)
fit1 = sampling(stanmodel,
data = data,            # named list of data
chains = 4,             # number of Markov chains
warmup = 1000,          # number of warmup iterations per chain
iter = 2000,            # total number of iterations per chain
cores = 1,              # number of cores (could use one per chain)
refresh = 0             # no progress shown
)
